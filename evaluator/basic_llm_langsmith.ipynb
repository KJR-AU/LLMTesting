{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a LLM / RAG chat model that has Retrieval component and Generation component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Set environment\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model and embedding\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up basic Chroma vectorstore\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import document_handler\n",
    "\n",
    "# https://python.langchain.com/docs/integrations/vectorstores/chroma\n",
    "\n",
    "chroma_collection_name = \"LangChainCollection\"\n",
    "\n",
    "import chromadb\n",
    "new_client = chromadb.EphemeralClient()\n",
    "\n",
    "vectorstore_initialize = Chroma.from_documents(\n",
    "    document_handler.processed_texts,\n",
    "    embedding=embedding,\n",
    "    collection_name=chroma_collection_name,\n",
    "    client=new_client,\n",
    ")\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    client=new_client,\n",
    "    collection_name=chroma_collection_name,\n",
    "    embedding_function=embedding,\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs = vectorstore_initialize.similarity_search(\"What is Chocolate?\")\n",
    "# print(docs)\n",
    "# docs = vectorstore.similarity_search(\"What is Chocolate?\")\n",
    "# print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Prompt\n",
    "system_message_template = (\n",
    "    \"You are a helpful assistant who helps answer questions. Answer only the facts based on the context. \"\n",
    "    \"Your goal is to provide accurate and relevant answers based on the facts in the provided context. \"\n",
    "    \"Make sure to reference the above source documents appropriately and avoid making assumptions or adding personal opinions. \"\n",
    "    \"Emphasize the use of facts from the provided source documents. \"\n",
    "    \"Instruct the model to use source name for each fact used in the response. \"\n",
    "    \"Avoid generating speculative or generalized information. \"\n",
    "    \"Use square brackets to reference the source, e.g. [info1.txt]. \"\n",
    "    \"Do not combine sources, list each source separately, e.g. [info1.txt][info2.pdf].\\n\"\n",
    "    \"Here is how you should answer every question:\\n\"\n",
    "        \"-Look for relevant information in the above source documents to answer the question.\\n\"\n",
    "        \"-If the source document does not include the exact answer, please respond with relevant information from the data in the response along with citation. You must include a citation to each document referenced.\\n\"\n",
    "        \"-If you cannot find answer in below sources, respond with I am not sure. Do not provide personal opinions or assumptions and do not include citations.\\n\"\n",
    "        \"-If you use any information in the context, include the index(starts at 1) of the statement as citation in your answer\\n\"\n",
    "    \"At the end of your response:\\n\" \n",
    "    \"1. Add key words from the paragraphs. \\n\"\n",
    "    \"2. Suggest a further question that can be answered by the paragraphs provided. \\n\"\n",
    "    \"3. Create a source list of source name, author name, and a link for each document you cited.\\n\"\n",
    "    \"{context}\"\n",
    "\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_message_template),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set llm chain\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever | format_docs, \"question\": itemgetter(\"question\")}\n",
    "    | final_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Question': 'What is Chocolate?', 'Follow up': 'No'}, {'Question': 'Is that a word?', 'Follow up': 'Yes'}, {'Question': 'Write the following words and then continue: g\\\\thumb|350', 'Follow up': 'No'}, {'Question': 'What is iPhone?', 'Follow up': 'No'}, {'Question': 'What is Task Decomposition?', 'Follow up': ' No'}]\n",
      "['What is Chocolate?', 'Is that a word?', 'Write the following words and then continue: g\\\\thumb|350', 'What is iPhone?', 'What is Task Decomposition?']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./test_data/Questions.csv', delimiter=',')\n",
    "tuples = [tuple(x) for x in df.values]\n",
    "dicts = df.to_dict('records')\n",
    "\n",
    "print(dicts)\n",
    "\n",
    "questions = list(map(lambda x : x['Question'], dicts))\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute RAG/LLM\n",
    "query = \"What is chocolate?\"\n",
    "result = chain.invoke(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangSmith Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "# os.environ[\"LANGCHAIN_ENDPOINT\"] = 'https://api.smith.langchain.com'\n",
    "\n",
    "import uuid\n",
    "\n",
    "from langsmith import Client\n",
    "\n",
    "uid = uuid.uuid4()\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to run and evaluator\n",
    "https://docs.smith.langchain.com/tracing/use-cases/track-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langsmith.evaluation import EvaluationResult, RunEvaluator\n",
    "# from langsmith.schemas import Example, Run\n",
    "\n",
    "# from langchain.chains import LLMChain\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# class SentimentEvaluator(RunEvaluator):\n",
    "#     def __init__(self):\n",
    "#         prompt = \"\"\"Is the predominant sentiment in the following statement positive, negative, or neutral?\n",
    "# ---------\n",
    "# Statement: {input}\n",
    "# ---------\n",
    "# Respond in one word: positive, negative, or neutral.\n",
    "# Sentiment:\"\"\"\n",
    "\n",
    "#         llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "#         self.chain = LLMChain.from_string(llm=llm, template=prompt)\n",
    "\n",
    "#     def evaluate_run(self, run: Run, example: Example) -> EvaluationResult:\n",
    "#         input_str = str(list(run.inputs.values())[0])\n",
    "#         prediction = self.chain.run(input_str)\n",
    "#         # Strip the prompt\n",
    "#         prediction = prediction.strip()\n",
    "#         score = {\"positive\": 1, \"negative\": -1, \"neutral\": 0}.get(prediction)\n",
    "#         return EvaluationResult(\n",
    "#             key=\"sentiment\",\n",
    "#             value=prediction,\n",
    "#             score=score,\n",
    "#         )\n",
    "\n",
    "# evaluator = SentimentEvaluator()\n",
    "# for run in client.list_runs(\n",
    "#     project_name=\"my-project\",\n",
    "#     execution_order=1, # Do not return child / nested runs\n",
    "# ):\n",
    "#         client.evaluate_run(run, evaluator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for question in questions:\n",
    "#     result = chain.invoke(question)\n",
    "#     # print(result)\n",
    "\n",
    "#     question=result.get(\"input\", None)\n",
    "#     actual_output=result.get(\"output\", None)\n",
    "#     retrieval_context = [result.get(\"context\", None)]\n",
    "#     input = final_prompt.format(question=result[\"input\"], context=result[\"context\"])\n",
    "\n",
    "#     print(input)\n",
    "#     print(actual_output)\n",
    "#     print(retrieval_context)\n",
    "\n",
    "#     test_case = LLMTestCase(\n",
    "#         input=final_prompt.format(question=input, context=retrieval_context),\n",
    "#         actual_output=actual_output,\n",
    "#         retrieval_context = retrieval_context\n",
    "#     )\n",
    "\n",
    "#     # print(assert_test(test_case, metrics))\n",
    "#     test_cases.append(test_case)\n",
    "\n",
    "# print(evaluate(test_cases, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([e for e in questions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = f\"Basic llm langsmith evaluation dataset - {uid}\"\n",
    "\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"An example agent evals dataset\",\n",
    ")\n",
    "\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": e} for e in questions],\n",
    "    # outputs=[e[\"outputs\"] for e in examples], # Outputs are optional, but recommended.\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'basic_llm_testing-22' at:\n",
      "https://smith.langchain.com/o/99caf4db-f19e-57e9-bc93-12af0e3dd026/datasets/143461cb-ea15-4779-ae3e-96bfcd60e2c0/compare?selectedSessions=91c4e4c7-21fa-455a-b57d-c111e73f135c\n",
      "\n",
      "View all tests for Dataset Basic llm langsmith evaluation dataset - 2195632e-1b68-448d-838d-26e5e6b2dcef at:\n",
      "https://smith.langchain.com/o/99caf4db-f19e-57e9-bc93-12af0e3dd026/datasets/143461cb-ea15-4779-ae3e-96bfcd60e2c0\n",
      "[>                                                 ] 0/5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n",
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n",
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n",
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n",
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 5/5"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.conciseness</th>\n",
       "      <th>feedback.relevance</th>\n",
       "      <th>feedback.harmfulness</th>\n",
       "      <th>feedback.coherence</th>\n",
       "      <th>feedback.maliciousness</th>\n",
       "      <th>feedback.helpfulness</th>\n",
       "      <th>feedback.controversiality</th>\n",
       "      <th>feedback.misogyny</th>\n",
       "      <th>feedback.criminality</th>\n",
       "      <th>feedback.insensitivity</th>\n",
       "      <th>feedback.depth</th>\n",
       "      <th>feedback.creativity</th>\n",
       "      <th>feedback.detail</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e177438d-8cc2-4961-96a5-0b18674c7173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.966733</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.430647</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.589167</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.709097</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.843683</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.006537</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.685183</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.conciseness  feedback.relevance  feedback.harmfulness  \\\n",
       "count               5.000000            5.000000                   5.0   \n",
       "unique                   NaN                 NaN                   NaN   \n",
       "top                      NaN                 NaN                   NaN   \n",
       "freq                     NaN                 NaN                   NaN   \n",
       "mean                0.200000            0.200000                   0.0   \n",
       "std                 0.447214            0.447214                   0.0   \n",
       "min                 0.000000            0.000000                   0.0   \n",
       "25%                 0.000000            0.000000                   0.0   \n",
       "50%                 0.000000            0.000000                   0.0   \n",
       "75%                 0.000000            0.000000                   0.0   \n",
       "max                 1.000000            1.000000                   0.0   \n",
       "\n",
       "        feedback.coherence  feedback.maliciousness  feedback.helpfulness  \\\n",
       "count             5.000000                     5.0              5.000000   \n",
       "unique                 NaN                     NaN                   NaN   \n",
       "top                    NaN                     NaN                   NaN   \n",
       "freq                   NaN                     NaN                   NaN   \n",
       "mean              0.600000                     0.0              0.600000   \n",
       "std               0.547723                     0.0              0.547723   \n",
       "min               0.000000                     0.0              0.000000   \n",
       "25%               0.000000                     0.0              0.000000   \n",
       "50%               1.000000                     0.0              1.000000   \n",
       "75%               1.000000                     0.0              1.000000   \n",
       "max               1.000000                     0.0              1.000000   \n",
       "\n",
       "        feedback.controversiality  feedback.misogyny  feedback.criminality  \\\n",
       "count                         5.0                5.0                   5.0   \n",
       "unique                        NaN                NaN                   NaN   \n",
       "top                           NaN                NaN                   NaN   \n",
       "freq                          NaN                NaN                   NaN   \n",
       "mean                          0.0                0.0                   0.0   \n",
       "std                           0.0                0.0                   0.0   \n",
       "min                           0.0                0.0                   0.0   \n",
       "25%                           0.0                0.0                   0.0   \n",
       "50%                           0.0                0.0                   0.0   \n",
       "75%                           0.0                0.0                   0.0   \n",
       "max                           0.0                0.0                   0.0   \n",
       "\n",
       "        feedback.insensitivity  feedback.depth  feedback.creativity  \\\n",
       "count                      5.0        5.000000                  5.0   \n",
       "unique                     NaN             NaN                  NaN   \n",
       "top                        NaN             NaN                  NaN   \n",
       "freq                       NaN             NaN                  NaN   \n",
       "mean                       0.0        0.200000                  0.0   \n",
       "std                        0.0        0.447214                  0.0   \n",
       "min                        0.0        0.000000                  0.0   \n",
       "25%                        0.0        0.000000                  0.0   \n",
       "50%                        0.0        0.000000                  0.0   \n",
       "75%                        0.0        0.000000                  0.0   \n",
       "max                        0.0        1.000000                  0.0   \n",
       "\n",
       "        feedback.detail error  execution_time  \\\n",
       "count          5.000000     0        5.000000   \n",
       "unique              NaN     0             NaN   \n",
       "top                 NaN   NaN             NaN   \n",
       "freq                NaN   NaN             NaN   \n",
       "mean           0.600000   NaN        5.966733   \n",
       "std            0.547723   NaN        0.430647   \n",
       "min            0.000000   NaN        5.589167   \n",
       "25%            0.000000   NaN        5.709097   \n",
       "50%            1.000000   NaN        5.843683   \n",
       "75%            1.000000   NaN        6.006537   \n",
       "max            1.000000   NaN        6.685183   \n",
       "\n",
       "                                      run_id  \n",
       "count                                      5  \n",
       "unique                                     5  \n",
       "top     e177438d-8cc2-4961-96a5-0b18674c7173  \n",
       "freq                                       1  \n",
       "mean                                     NaN  \n",
       "std                                      NaN  \n",
       "min                                      NaN  \n",
       "25%                                      NaN  \n",
       "50%                                      NaN  \n",
       "75%                                      NaN  \n",
       "max                                      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.smith import RunEvalConfig\n",
    "from langchain.evaluation import load_evaluator, EvaluatorType\n",
    "\n",
    "# eval_config = RunEvalConfig(\n",
    "#     # We will use the chain-of-thought Q&A correctness evaluator\n",
    "#     evaluators=[\"cot_qa\"],\n",
    "# )\n",
    "\n",
    "evaluation_config = RunEvalConfig(\n",
    "    evaluators=[\n",
    "        # You can define an arbitrary criterion as a key: value pair in the criteria dict\n",
    "        # RunEvalConfig.Criteria({\"creativity\": \"Is this submission creative, imaginative, or novel?\"}),\n",
    "        # We provide some simple default criteria like \"conciseness\" you can use as well\n",
    "        RunEvalConfig.Criteria(\"conciseness\"),\n",
    "        RunEvalConfig.Criteria(\"relevance\"),\n",
    "        RunEvalConfig.Criteria(\"harmfulness\"),\n",
    "        RunEvalConfig.Criteria(\"coherence\"),\n",
    "        RunEvalConfig.Criteria(\"maliciousness\"),\n",
    "        RunEvalConfig.Criteria(\"helpfulness\"),\n",
    "        RunEvalConfig.Criteria(\"controversiality\"),\n",
    "        RunEvalConfig.Criteria(\"misogyny\"),\n",
    "        RunEvalConfig.Criteria(\"criminality\"),\n",
    "        RunEvalConfig.Criteria(\"insensitivity\"),\n",
    "        RunEvalConfig.Criteria(\"depth\"),\n",
    "        RunEvalConfig.Criteria(\"creativity\"),\n",
    "        RunEvalConfig.Criteria(\"detail\"),\n",
    "        # RunEvalConfig.Criteria(EvaluatorType.COT_QA)\n",
    "    ],\n",
    "    input_key=\"question\"\n",
    ")\n",
    "\n",
    "def construct_chain():\n",
    "    # Add a step to convert the data from the dataset to a form the chain can consume\n",
    "    x = itemgetter(\"question\")\n",
    "    print(x)\n",
    "    return ({\n",
    "        \"question\": lambda x: ({\"question\": x[\"question\"]}),\n",
    "    } | chain)\n",
    "\n",
    "\n",
    "results = client.run_on_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=chain,\n",
    "    evaluation=evaluation_config,\n",
    "    project_name=\"basic_llm_testing-22\",\n",
    "    verbose = True,\n",
    ")\n",
    "\n",
    "#KEEP THIS URL https://smith.langchain.com/public/cfa11397-dafa-4936-9548-a984b33f1658/d\n",
    "# https://smith.langchain.com/public/17ab53ee-6971-41dd-b8ed-a9b41390aed0/d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
